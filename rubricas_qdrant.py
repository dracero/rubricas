"""
============================================================================
SISTEMA COLABA QDRANT - Generaci√≥n de R√∫bricas con Vector Search & LangSmith
============================================================================

Sistema multi-agente para generar r√∫bricas acad√©micas utilizando:
- Qdrant: Base de datos vectorial para persistencia y RAG
- LangSmith: Trazabilidad y observabilidad
- Google Gemini: LLM para razonamiento y generaci√≥n
"""

import json
import re
import logging
import os
import time
import threading
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime
import hashlib
from collections import defaultdict

# Google Generative AI
from google import genai
from google.genai import types
from google.adk.agents import Agent

# Sentence Transformers
from sentence_transformers import SentenceTransformer

# Qdrant
try:
    from qdrant_client import QdrantClient
    from qdrant_client.http import models as qmodels
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    print("‚ö†Ô∏è Qdrant Client no instalado. Ejecuta: pip install qdrant-client")

# LangSmith con OpenTelemetry (m√©todo correcto para ADK)
try:
    from langsmith.integrations.otel import configure as configure_langsmith_otel
    LANGSMITH_AVAILABLE = True
except ImportError:
    LANGSMITH_AVAILABLE = False
    configure_langsmith_otel = None
    print("‚ö†Ô∏è LangSmith SDK no instalado. Ejecuta: pip install langsmith>=0.4.26")

# Decorador traceable (fallback si no est√° disponible)
try:
    from langsmith import traceable
    from langsmith.run_helpers import get_current_run_tree
except ImportError:
    def traceable(*args, **kwargs):
        def decorator(func):
            return func
        return decorator
    
    def get_current_run_tree():
        return None

# Para Colab Secrets
try:
    from google.colab import userdata
    USING_COLAB = True
except ImportError:
    USING_COLAB = False


# ============================================================================
# CONFIGURACI√ìN LANGSMITH
# ============================================================================

def setup_langsmith():
    """Configurar LangSmith con OpenTelemetry para ADK"""
    if not LANGSMITH_AVAILABLE:
        return False
        
    try:
        # Intentar obtener API Key
        api_key = os.environ.get("LANGSMITH_API_KEY")
        if not api_key and USING_COLAB:
            try:
                api_key = userdata.get("LANGSMITH_API_KEY")
            except:
                pass
        
        if not api_key:
            print("‚ö†Ô∏è LangSmith: No API Key found.")
            return False

        # Configurar variables de entorno
        os.environ["LANGSMITH_API_KEY"] = api_key
        project_name = "rubricas_qdrant_system"
        os.environ["LANGSMITH_PROJECT"] = project_name
        
        # Configurar OpenTelemetry con LangSmith
        configure_langsmith_otel(project_name=project_name)
        
        print(f"‚úÖ LangSmith configurado con OpenTelemetry (proyecto: {project_name})")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è Error configurando LangSmith: {e}")
        return False


# ============================================================================
# CONFIGURACI√ìN GENERAL
# ============================================================================

class ConfiguracionColaba:
    def __init__(self):
        self.GOOGLE_API_KEY = self._get_secret("GOOGLE_API_KEY")
        self.QDRANT_URL = self._get_secret("QDRANT_URL")
        self.QDRANT_API_KEY = self._get_secret("QDRANT_KEY")
        
        # Modelo de Embeddings
        self.EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
        
        # Validaci√≥n
        if not self.GOOGLE_API_KEY:
            raise ValueError("Falta GOOGLE_API_KEY")
        if not self.QDRANT_URL:
            print("‚ö†Ô∏è Advertencia: Falta QDRANT_URL, se usar√° modo memoria si es posible o fallar√°.")

    def _get_secret(self, key: str) -> str:
        # 1. Intentar variable de entorno
        val = os.environ.get(key)
        if val: return val
        
        # 2. Si estamos en Colab, intentar userdata
        if USING_COLAB:
            try:
                return userdata.get(key)
            except:
                return None
        return None


# ============================================================================
# ONTOLOG√çA IEEE LOM (IEEE 1484.12.1-2020) - Constantes y Esquema
# ============================================================================

# Roles de usuario seg√∫n IEEE LOM Educational
IEEE_LOM_ROLES = {
    "teacher": "Docente/Profesor",
    "author": "Autor de contenido",
    "learner": "Estudiante/Aprendiz", 
    "manager": "Gestor/Administrador"
}

# Contextos educativos IEEE LOM
IEEE_LOM_CONTEXTS = {
    "school": "Educaci√≥n escolar (primaria/secundaria)",
    "higher education": "Educaci√≥n superior universitaria",
    "training": "Formaci√≥n profesional/capacitaci√≥n",
    "other": "Otro contexto educativo"
}

# Tipos de recursos de aprendizaje IEEE LOM
IEEE_LOM_RESOURCE_TYPES = [
    "exercise", "simulation", "questionnaire", "diagram", "figure",
    "graph", "index", "slide", "table", "narrative text", "exam",
    "experiment", "problem statement", "self assessment", "lecture",
    "policy document", "evaluation rubric", "reference"
]

# Niveles de densidad sem√°ntica IEEE LOM
IEEE_LOM_SEMANTIC_DENSITY = ["very low", "low", "medium", "high", "very high"]

# Estructura del esquema IEEE LOM para validaci√≥n
IEEE_LOM_SCHEMA = {
    "general": {
        "identifier": {"catalog": str, "entry": str},
        "title": str,
        "language": str,
        "description": str,
        "keyword": list,
        "structure": ["hierarchical", "collection", "networked", "branched", "linear"],
        "aggregationLevel": ["1", "2", "3", "4"]
    },
    "lifeCycle": {
        "version": str,
        "status": ["draft", "final", "revised", "unavailable"],
        "contribute": list
    },
    "educational": {
        "interactivityType": ["active", "expositive", "mixed"],
        "learningResourceType": list,
        "interactivityLevel": IEEE_LOM_SEMANTIC_DENSITY,
        "semanticDensity": IEEE_LOM_SEMANTIC_DENSITY,
        "intendedEndUserRole": list,
        "context": list,
        "typicalAgeRange": str,
        "difficulty": ["very easy", "easy", "medium", "difficult", "very difficult"],
        "typicalLearningTime": str
    },
    "rights": {
        "cost": ["yes", "no"],
        "copyrightAndOtherRestrictions": ["yes", "no"],
        "description": str
    },
    "relation": list,
    "classification": list
}

# Niveles educativos para adaptaci√≥n de r√∫bricas
NIVELES_ESTUDIANTE = {
    "primer_a√±o": {
        "nombre": "Primer A√±o Universitario",
        "max_criterios": 5,
        "lenguaje": "simple y directo, evitando jerga t√©cnica innecesaria",
        "ejemplos_requeridos": True,
        "descripcion": "R√∫brica simplificada con criterios b√°sicos y claros"
    },
    "avanzado": {
        "nombre": "Estudiante Avanzado (3¬∞-5¬∞ a√±o)",
        "max_criterios": 12,
        "lenguaje": "t√©cnico-acad√©mico apropiado para el nivel",
        "ejemplos_requeridos": True,
        "descripcion": "R√∫brica intermedia con criterios detallados"
    },
    "posgrado": {
        "nombre": "Posgrado/Investigaci√≥n",
        "max_criterios": 20,
        "lenguaje": "especializado y preciso",
        "ejemplos_requeridos": False,
        "descripcion": "R√∫brica exhaustiva con todos los criterios"
    }
}


def validar_metadatos_lom(metadatos: Dict) -> Tuple[bool, List[str]]:
    """
    Valida que los metadatos cumplan con el esquema IEEE LOM.
    
    Args:
        metadatos: Diccionario con metadatos a validar
        
    Returns:
        Tuple con (es_valido, lista_de_errores)
    """
    errores = []
    
    # Campos obligatorios de General
    if "general" not in metadatos:
        errores.append("Falta categor√≠a 'general' (obligatoria)")
    else:
        general = metadatos["general"]
        if not general.get("title"):
            errores.append("Falta 'general.title' (obligatorio)")
        if not general.get("description"):
            errores.append("Falta 'general.description' (obligatorio)")
        if not general.get("language"):
            errores.append("Falta 'general.language' (obligatorio)")
    
    # Validar Educational si existe
    if "educational" in metadatos:
        edu = metadatos["educational"]
        if edu.get("context"):
            contextos = edu["context"] if isinstance(edu["context"], list) else [edu["context"]]
            for ctx in contextos:
                if ctx not in IEEE_LOM_CONTEXTS:
                    errores.append(f"Contexto educativo '{ctx}' no v√°lido. Use: {list(IEEE_LOM_CONTEXTS.keys())}")
    
    return len(errores) == 0, errores


# ============================================================================
# ESTRUCTURAS DE DATOS (Mantenidas de rubricas.py)
# ============================================================================

@dataclass
class Entidad:
    """Representa una entidad en la ontolog√≠a"""
    nombre: str
    tipo: str
    propiedades: Dict[str, Any]
    contexto: str
    embedding: Optional[List[float]] = None
    fecha_creacion: Optional[str] = None
    validada: bool = False
    
    def to_dict(self):
        return {
            "nombre": self.nombre,
            "tipo": self.tipo,
            "propiedades": self.propiedades,
            "contexto": self.contexto,
            "validada": self.validada,
            "fecha_creacion": self.fecha_creacion or datetime.now().isoformat()
        }

@dataclass
class Relacion:
    """Representa una relaci√≥n entre entidades"""
    origen: str
    destino: str
    tipo: str
    propiedades: Dict[str, Any]
    confianza: float = 1.0
    
    def to_dict(self):
        return {
            "origen": self.origen,
            "destino": self.destino,
            "tipo": self.tipo,
            "propiedades": self.propiedades,
            "confianza": self.confianza
        }

@dataclass
class Ontologia:
    """Estructura completa de la ontolog√≠a"""
    entidades: List[Entidad]
    relaciones: List[Relacion]
    metadata: Dict[str, Any]


# ============================================================================
# UTILAJE: RATE LIMITER Y CACHE (Reutilizados)
# ============================================================================

class GlobalRateLimiter:
    _instance = None
    _lock = threading.Lock()
    _last_call = 0
    _min_interval = 1.0 # Configurable
    _call_count = 0

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(GlobalRateLimiter, cls).__new__(cls)
            return cls._instance

    def wait(self):
        with self._lock:
            self._call_count += 1
            now = time.time()
            elapsed = now - self._last_call
            if elapsed < self._min_interval:
                time.sleep(self._min_interval - elapsed)
            self._last_call = time.time()

rate_limiter = GlobalRateLimiter()

class LLMCache:
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(LLMCache, cls).__new__(cls)
                cls._instance._cache = {}
            return cls._instance
    
    def get(self, prompt):
        key = hashlib.md5(prompt[:1000].encode()).hexdigest()
        return self._cache.get(key)
        
    def set(self, prompt, response):
        key = hashlib.md5(prompt[:1000].encode()).hexdigest()
        self._cache[key] = response

llm_cache = LLMCache()

def limpiar_json_respuesta(texto: str) -> str:
    """
    Limpia una respuesta JSON que puede tener errores de formato comunes.
    Maneja: comas trailing, comillas no escapadas, saltos de l√≠nea en strings, etc.
    """
    if not texto:
        return "{}"
    
    # Remover bloques de c√≥digo markdown si existen
    texto = re.sub(r'^```json\s*', '', texto.strip())
    texto = re.sub(r'^```\s*', '', texto)
    texto = re.sub(r'\s*```$', '', texto)
    
    # Encontrar el JSON (buscar desde { hasta el √∫ltimo })
    inicio = texto.find('{')
    fin = texto.rfind('}')
    if inicio != -1 and fin != -1 and fin > inicio:
        texto = texto[inicio:fin + 1]
    
    # Remover comas trailing antes de } o ]
    texto = re.sub(r',\s*}', '}', texto)
    texto = re.sub(r',\s*]', ']', texto)
    
    # Escapar saltos de l√≠nea dentro de strings JSON
    # Reemplazar newlines literales que no est√°n escapados
    texto = texto.replace('\r\n', '\\n').replace('\r', '\\n')
    
    # Reemplazar tabs por espacios
    texto = texto.replace('\t', ' ')
    
    # Remover caracteres de control problem√°ticos (excepto \n y \t ya procesados)
    texto = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', texto)
    
    return texto


def parsear_json_con_fallback(texto: str) -> dict:
    """
    Intenta parsear JSON con m√∫ltiples estrategias de fallback.
    """
    # 1. Intentar parse directo
    try:
        return json.loads(texto)
    except json.JSONDecodeError:
        pass
    
    # 2. Limpiar y reintentar
    texto_limpio = limpiar_json_respuesta(texto)
    try:
        return json.loads(texto_limpio)
    except json.JSONDecodeError as e:
        print(f"   ‚ö†Ô∏è JSON inv√°lido despu√©s de limpieza: {e}")
        print(f"   üìù Fragmento problem√°tico: ...{texto_limpio[max(0, e.pos-50):e.pos+50]}...")
    
    # 3. Fallback: extraer entidades y relaciones con regex
    print("   üîß Intentando extracci√≥n con regex como fallback...")
    resultado = {"entidades": [], "relaciones": []}
    
    # Extraer entidades con regex
    entidad_pattern = r'"nombre"\s*:\s*"([^"]+)"\s*,\s*"tipo"\s*:\s*"([^"]+)"'
    for match in re.finditer(entidad_pattern, texto_limpio):
        resultado["entidades"].append({
            "nombre": match.group(1),
            "tipo": match.group(2),
            "contexto": "",
            "propiedades": {}
        })
    
    # Extraer relaciones con regex
    relacion_pattern = r'"origen"\s*:\s*"([^"]+)"\s*,\s*"destino"\s*:\s*"([^"]+)"\s*,\s*"tipo"\s*:\s*"([^"]+)"'
    for match in re.finditer(relacion_pattern, texto_limpio):
        resultado["relaciones"].append({
            "origen": match.group(1),
            "destino": match.group(2),
            "tipo": match.group(3),
            "propiedades": {}
        })
    
    if resultado["entidades"]:
        print(f"   ‚úÖ Fallback exitoso: {len(resultado['entidades'])} entidades, {len(resultado['relaciones'])} relaciones")
    
    return resultado

def llamar_llm_con_retry(func, prompt_for_cache=None, max_intentos=3):
    if prompt_for_cache:
        cached = llm_cache.get(prompt_for_cache)
        if cached: return cached
        
    for i in range(max_intentos):
        try:
            rate_limiter.wait()
            res = func()
            if prompt_for_cache: llm_cache.set(prompt_for_cache, res)
            return res
        except Exception as e:
            if i == max_intentos - 1: raise e
            time.sleep(2 ** i)


# ============================================================================
# AGENTE PERSISTENCIA QDRANT
# ============================================================================

class AgentePersistenciaQdrant:
    """Gestiona la persistencia en Qdrant Vector DB"""
    
    def __init__(self, config: ConfiguracionColaba):
        self.config = config
        self.client = QdrantClient(
            url=config.QDRANT_URL,
            api_key=config.QDRANT_API_KEY
        )
        self.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL_NAME)
        self.collection_name = "rubricas_entidades"
        
        self._inicializar_coleccion()

    def _inicializar_coleccion(self):
        """Crea la colecci√≥n si no existe"""
        try:
            collections = self.client.get_collections()
            exists = any(c.name == self.collection_name for c in collections.collections)
            
            if not exists:
                print(f"üì¶ Creando colecci√≥n Qdrant: {self.collection_name}")
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=qmodels.VectorParams(
                        size=384,  # all-MiniLM-L6-v2 dimension
                        distance=qmodels.Distance.COSINE
                    )
                )
        except Exception as e:
            print(f"‚ö†Ô∏è Error inicializando Qdrant: {e}")

    def generar_embedding(self, texto: str) -> List[float]:
        return self.embedding_model.encode(texto).tolist()

    def guardar_ontologia(self, ontologia: Ontologia):
        """Guarda entidades y relaciones en Qdrant"""
        points = []
        
        # Mapear relaciones por entidad origen para guardarlas en payload
        relaciones_por_entidad = defaultdict(list)
        for rel in ontologia.relaciones:
            relaciones_por_entidad[rel.origen].append(rel.to_dict())
            
        for entidad in ontologia.entidades:
            # Generar ID determinista basado en nombre
            point_id = hashlib.md5(entidad.nombre.encode()).hexdigest()
            
            # Generar embedding del contexto + nombre
            texto_embedding = f"{entidad.nombre}: {entidad.contexto}"
            vector = self.generar_embedding(texto_embedding)
            
            # Construir payload
            payload = entidad.to_dict()
            payload["relaciones_salientes"] = relaciones_por_entidad[entidad.nombre]
            
            points.append(qmodels.PointStruct(
                id=point_id,
                vector=vector,
                payload=payload
            ))
            
        # Upsert en lotes
        if points:
            try:
                self.client.upsert(
                    collection_name=self.collection_name,
                    points=points
                )
                print(f"‚úÖ Guardadas {len(points)} entidades en Qdrant")
                return True
            except Exception as e:
                print(f"‚ùå Error guardando en Qdrant: {e}")
                return False
        return False

    @traceable(name="AgentePersistenciaQdrant.buscar_similares", run_type="retriever")
    def buscar_similares(self, texto_consulta: str, limit: int = 5, score_threshold: float = 0.7) -> List[Dict]:
        """Busca entidades similares por vector (trazado via OpenTelemetry)"""
        vector = self.generar_embedding(texto_consulta)
        
        try:
            # Usar query_points (API moderna de qdrant-client 1.7+)
            result = self.client.query_points(
                collection_name=self.collection_name,
                query=vector,
                limit=limit,
                score_threshold=score_threshold
            )
            
            # Obtener puntos del resultado
            hits = result.points if hasattr(result, 'points') else result
            
            resultados = []
            scores = []
            for hit in hits:
                payload = hit.payload.copy() if hit.payload else {}
                score = hit.score
                payload['score'] = score
                scores.append(score)
                resultados.append(payload)
            
            # Log de m√©tricas para observabilidad
            avg_score = sum(scores) / len(scores) if scores else 0
            print(f"   üìä Qdrant Search: {len(resultados)} hits, avg_score: {avg_score:.3f}, threshold: {score_threshold}")
                
            return resultados
        except Exception as e:
            print(f"‚ö†Ô∏è Error en b√∫squeda Qdrant: {e}")
            return []


# ============================================================================
# AGENTE 1: ONT√ìLOGO (ADAPTADO QDRANT)
# ============================================================================

class AgenteOntologo:
    """Agente que extrae entidades y relaciones de textos normativos"""

    def __init__(self, config: ConfiguracionColaba):
        self.config = config
        self.client = genai.Client(api_key=config.GOOGLE_API_KEY)
        self.agent = Agent(
            name="ontologo",
            model="gemini-2.5-flash",
            instruction="Eres un experto en ontolog√≠as educativas. Extrae conceptos y relaciones.",
            description="Extrae entidades y relaciones"
        )
        self.token_limit = 60000  # L√≠mite amplio para respuestas JSON completas

    @traceable(name="AgenteOntologo.procesar_documento", run_type="chain")
    def procesar_documento(self, texto: str) -> Ontologia:
        """Procesa un documento y extrae una ontolog√≠a (trazado via OpenTelemetry)"""
        prompt = self._construir_prompt_extraccion(texto)
        
        # Estimar tokens de entrada
        input_chars = len(prompt)
        estimated_input_tokens = input_chars // 4
        print(f"   üìä Prompt ontolog√≠a: ~{estimated_input_tokens:,} tokens estimados")
        
        token_usage = {}
        
        def hacer_llamada():
            nonlocal token_usage
            response = self.client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=self.token_limit,
                    response_mime_type="application/json"
                )
            )
            
            # Capturar tokens reales de Gemini
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                token_usage = {
                    "prompt_tokens": getattr(response.usage_metadata, 'prompt_token_count', 0),
                    "completion_tokens": getattr(response.usage_metadata, 'candidates_token_count', 0),
                    "total_tokens": getattr(response.usage_metadata, 'total_token_count', 0)
                }
            
            return response.text

        try:
            print("üî¨ [Agente Ont√≥logo] Extrayendo entidades y relaciones...")
            resultado = llamar_llm_con_retry(hacer_llamada)
            
            # Mostrar tokens reales y registrar en LangSmith
            if token_usage:
                print(f"   üìä Tokens Gemini: {token_usage.get('prompt_tokens', 0):,} in, {token_usage.get('completion_tokens', 0):,} out")
                
                # Registrar en LangSmith si est√° activo
                rt = get_current_run_tree()
                if rt:
                    rt.add_metadata({
                        "token_usage": token_usage,
                        "model": "gemini-2.5-flash"
                    })
            
            # Parsear respuesta JSON con fallback robusto
            data = parsear_json_con_fallback(resultado)
            
            entidades = []
            relaciones = []
            
            # Procesar entidades
            for e in data.get("entidades", []):
                entidades.append(Entidad(
                    nombre=e["nombre"],
                    tipo=e["tipo"],
                    propiedades=e.get("propiedades", {}),
                    contexto=e.get("contexto", ""),
                    fecha_creacion=datetime.now().isoformat()
                ))
                
            # Procesar relaciones
            for r in data.get("relaciones", []):
                relaciones.append(Relacion(
                    origen=r["origen"],
                    destino=r["destino"],
                    tipo=r["tipo"],
                    propiedades=r.get("propiedades", {}),
                    confianza=r.get("confianza", 1.0)
                ))
            
            print(f"   üìä Ontolog√≠a extra√≠da: {len(entidades)} entidades, {len(relaciones)} relaciones")
            return Ontologia(entidades=entidades, relaciones=relaciones, metadata=token_usage)
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en Agente Ont√≥logo: {e}")
            return Ontologia([], [], {})

    def _construir_prompt_extraccion(self, texto: str) -> str:
        return f"""
        Analiza el siguiente texto normativo y extrae una ONTOLOG√çA de conceptos educativos.
        
        TEXTO:
        {texto[:20000]}  # L√≠mite de contexto
        
        INSTRUCCIONES:
        1. Identifica ENTIDADES clave: conceptos, criterios, niveles, requisitos.
        2. Identifica RELACIONES (M√çNIMO 3 por entidad):
           - REQUIERE, COMPLEMENTA, DEFINE, EJEMPLIFICA, PERTENECE_A, ES_PARTE_DE.
           - Busca relaciones expl√≠citas e IMPL√çCITAS.
           - Conecta densamente los conceptos.
        3. Normaliza nombres (snake_case preferiblemente para IDs).
        
        Responde SOLO con JSON con estructura:
        {{
          "entidades": [
            {{ "nombre": "id_unico", "tipo": "concepto", "contexto": "definici√≥n breve", "propiedades": {{...}} }}
          ],
          "relaciones": [
            {{ "origen": "id_1", "destino": "id_2", "tipo": "REQUIERE" }}
          ]
        }}
        """

# ============================================================================
# AGENTE 2: RUBRICADOR (OUTPUT EXTENDED)
# ============================================================================

class AgenteRubricador:
    """Genera r√∫bricas usando RAG y Gemini"""
    
    def __init__(self, config: ConfiguracionColaba):
        self.config = config
        self.client = genai.Client(api_key=config.GOOGLE_API_KEY)
        self.agent = Agent(
            name="rubricador",
            model="gemini-2.5-flash", 
            instruction="Experto en evaluaci√≥n educativa y dise√±o de r√∫bricas.",
            description="Genera r√∫bricas detalladas"
        )
        # L√≠mite amplio para documentos extensos
        self.max_tokens = 60000 

    @traceable(name="AgenteRubricador.generar_rubrica", run_type="chain")
    def generar_rubrica(self, prompt_usuario: str, contexto_rag: Dict, nivel: str = "avanzado") -> str:
        """Genera la r√∫brica final adaptada al nivel educativo con tracking completo"""
        
        # Obtener configuraci√≥n del nivel
        config_nivel = NIVELES_ESTUDIANTE.get(nivel, NIVELES_ESTUDIANTE["avanzado"])
        
        # Formatear contexto de Qdrant con scores
        contexto_str = ""
        qdrant_scores = []
        for item in contexto_rag.get("resultados", []):
            score = item.get('score', 0)
            qdrant_scores.append(score)
            contexto_str += f"- [{score:.3f}] [{item.get('nombre', 'N/A')}]: {item.get('contexto', '')[:300]}\n"
            if 'relaciones_salientes' in item:
                for rel in item['relaciones_salientes']:
                    contexto_str += f"  -> {rel['tipo']} -> {rel['destino']}\n"
        
        avg_qdrant_score = sum(qdrant_scores) / len(qdrant_scores) if qdrant_scores else 0
        
        # Instrucciones adaptadas al nivel
        instrucciones_nivel = f"""
        ADAPTACI√ìN AL NIVEL EDUCATIVO: {config_nivel['nombre']}
        - M√°ximo de criterios a incluir: {config_nivel['max_criterios']}
        - Estilo de lenguaje: {config_nivel['lenguaje']}
        - Incluir ejemplos concretos: {'S√ç, obligatorio' if config_nivel['ejemplos_requeridos'] else 'Opcional'}
        - Descripci√≥n: {config_nivel['descripcion']}
        """
        
        prompt_generacion = f"""
        Eres un ARQUITECTO PEDAG√ìGICO experto en dise√±o de instrumentos de evaluaci√≥n.
        
        SOLICITUD: {prompt_usuario}
        
        {instrucciones_nivel}
        
        CONTEXTO NORMATIVO (Base de Conocimiento - {len(qdrant_scores)} documentos, avg_score: {avg_qdrant_score:.3f}):
        {contexto_str}
        
        TAREA:
        Generar una R√öBRICA DE EVALUACI√ìN adaptada al nivel indicado.
        
        ESTRUCTURA OBLIGATORIA:
        1. INFORMACI√ìN GENERAL (Materia, Nivel, Objetivos)
        2. COMPETENCIAS A EVALUAR (Cognitivas, Procedimentales, Actitudinales)
        3. MATRIZ DE EVALUACI√ìN (Dimensiones, Criterios, Escala 1-4, Evidencias observables)
        4. NIVELES DE DOMINIO con ejemplos espec√≠ficos de qu√© constituye cada nivel
        5. RECOMENDACIONES AL ESTUDIANTE
        
        REGLAS CR√çTICAS:
        - NO uses t√©rminos vagos como "efectivo" o "adecuado" sin definirlos.
        - Cada criterio debe tener EVIDENCIAS OBSERVABLES (qu√© se puede ver/medir).
        - Incluye REQUISITOS M√çNIMOS concretos para aprobar.
        - Usa Markdown.
        - Respeta el l√≠mite de {config_nivel['max_criterios']} criterios principales.
        """
        
        # Estimar tokens de entrada
        input_chars = len(prompt_generacion)
        estimated_input_tokens = input_chars // 4
        print(f"   üìä Prompt r√∫brica: ~{estimated_input_tokens:,} tokens, contexto RAG: {len(contexto_str)} chars")
        
        token_usage = {}
        
        @traceable(name="Gemini.generar_fragmento", run_type="llm")
        def _llamar_modelo_trazado(contenido_prompt: str) -> Any:
            """Llamada individual trazada para LangSmith"""
            return self.client.models.generate_content(
                model='gemini-2.5-flash',
                contents=contenido_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.4,
                    max_output_tokens=self.max_tokens,
                )
            )

        def hacer_llamada_con_continuacion():
            """Genera la r√∫brica con continuaci√≥n autom√°tica si se trunca"""
            nonlocal token_usage
            
            respuesta_completa = ""
            contexto_continuacion = prompt_generacion
            max_continuaciones = 5
            continuaciones = 0
            
            while continuaciones < max_continuaciones:
                # Usar la funci√≥n trazada en lugar de llamar directo
                response = _llamar_modelo_trazado(contexto_continuacion)
                
                # Capturar tokens reales de Gemini
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    prev_tokens = token_usage.get('total_tokens', 0)
                    token_usage = {
                        "prompt_tokens": token_usage.get('prompt_tokens', 0) + getattr(response.usage_metadata, 'prompt_token_count', 0),
                        "completion_tokens": token_usage.get('completion_tokens', 0) + getattr(response.usage_metadata, 'candidates_token_count', 0),
                        "total_tokens": prev_tokens + getattr(response.usage_metadata, 'total_token_count', 0)
                    }
                    
                    # Registrar tokens para ESTA llamada espec√≠fica en su propio trace
                    rt = get_current_run_tree()
                    if rt:
                        rt.add_metadata({
                            "token_usage_call": {
                                "prompt": getattr(response.usage_metadata, 'prompt_token_count', 0),
                                "completion": getattr(response.usage_metadata, 'candidates_token_count', 0)
                            }
                        })
                
                texto_parcial = response.text if response.text else ""
                respuesta_completa += texto_parcial
                
                # Verificar si la respuesta est√° completa
                finish_reason = None
                if response.candidates and len(response.candidates) > 0:
                    finish_reason = response.candidates[0].finish_reason
                
                if finish_reason == "STOP" or finish_reason is None:
                    # Respuesta completa
                    break
                elif str(finish_reason) in ["MAX_TOKENS", "2", "FinishReason.MAX_TOKENS"]:
                    # Respuesta truncada, pedir continuaci√≥n
                    continuaciones += 1
                    print(f"   ‚ö†Ô∏è Respuesta truncada (parte {continuaciones}), solicitando continuaci√≥n...")
                    
                    # Nuevo prompt pidiendo continuar
                    contexto_continuacion = f"""
                    Contin√∫a EXACTAMENTE donde quedaste. Esta es la continuaci√≥n de una r√∫brica que estabas generando.
                    
                    √öLTIMO FRAGMENTO GENERADO (para contexto):
                    ...{texto_parcial[-500:]}
                    
                    INSTRUCCI√ìN: Contin√∫a desde ese punto. NO repitas lo anterior. Solo contin√∫a la r√∫brica.
                    """
                else:
                    print(f"   ‚ö†Ô∏è Respuesta finalizada por: {finish_reason}")
                    break
            
            if continuaciones > 0:
                print(f"   ‚úÖ R√∫brica completada con {continuaciones} continuaci√≥n(es)")
            
            return respuesta_completa

        try:
            print(f"‚úçÔ∏è [Agente Rubricador] Generando r√∫brica para nivel: {config_nivel['nombre']}...")
            resultado = llamar_llm_con_retry(hacer_llamada_con_continuacion)
            
            if resultado:
                # Mostrar tokens reales y registrar en LangSmith
                if token_usage:
                    print(f"   üìä Tokens Gemini: {token_usage.get('prompt_tokens', 0):,} in, {token_usage.get('completion_tokens', 0):,} out")
                    
                    # Registrar en LangSmith si est√° activo
                    rt = get_current_run_tree()
                    if rt:
                        rt.add_metadata({
                            "token_usage": token_usage,
                            "model": "gemini-2.5-flash", 
                            "continuaciones": continuaciones if 'continuaciones' in locals() else 0
                        })
                else:
                    estimated_output_tokens = len(resultado) // 4
                    print(f"   üìä Respuesta r√∫brica: ~{estimated_output_tokens:,} tokens (estimado)")
                
                print(f"   üìä Qdrant context: {len(qdrant_scores)} docs, avg_score: {avg_qdrant_score:.3f}")
                print(f"   üìä Longitud final: {len(resultado):,} caracteres")
            
            return resultado
        except Exception as e:
            print(f"‚ö†Ô∏è Error generando r√∫brica: {e}")
            return "Error en generaci√≥n."

# ============================================================================
# AGENTE 3: B√öSQUEDA (ADAPTADO)
# ============================================================================

class AgenteBusqueda:
    """Coordina b√∫squedas en Qdrant con tracking"""
    
    def __init__(self, config: ConfiguracionColaba, persistencia: AgentePersistenciaQdrant):
        self.config = config
        self.persistencia = persistencia
    
    @traceable(name="AgenteBusqueda.procesar_prompt", run_type="retriever")
    def procesar_prompt(self, prompt: str) -> Dict:
        """Procesa prompt y busca contexto en Qdrant con m√©tricas"""
        print(f"üîé [Agente B√∫squeda] Buscando informaci√≥n para: '{prompt[:50]}...'")
        
        # B√∫squeda sem√°ntica directa
        resultados = self.persistencia.buscar_similares(prompt, limit=15)
        
        # Extraer scores para m√©tricas
        scores = [r.get('score', 0) for r in resultados]
        avg_score = sum(scores) / len(scores) if scores else 0
        
        print(f"   üìä B√∫squeda completada: {len(resultados)} resultados, avg_score: {avg_score:.3f}")
        
        return {
            "prompt": prompt,
            "resultados": resultados,
            "cantidad": len(resultados),
            "scores": scores,
            "avg_score": avg_score
        }

# ============================================================================
# SISTEMA PRINCIPAL
# ============================================================================

class SistemaColabaQdrant:
    """Orquestador del sistema con Qdrant y LangSmith"""
    
    def __init__(self):
        print("üöÄ Iniciando Sistema Colaba (Edici√≥n Qdrant)...")
        self.langsmith_enabled = setup_langsmith()
        
        self.config = ConfiguracionColaba()
        self.agente_persistencia = AgentePersistenciaQdrant(self.config)
        self.agente_ontologo = AgenteOntologo(self.config)
        self.agente_rubricador = AgenteRubricador(self.config)
        self.agente_busqueda = AgenteBusqueda(self.config, self.agente_persistencia)

    @traceable(name="SistemaColaba.cargar_normativa", run_type="chain")
    def cargar_normativa(self, texto_normativa: str):
        """Procesa y guarda una normativa (trazado via OpenTelemetry)"""
        ontologia = self.agente_ontologo.procesar_documento(texto_normativa)
        if ontologia.entidades:
            self.agente_persistencia.guardar_ontologia(ontologia)
            print(f"‚úÖ Normativa cargada: {len(ontologia.entidades)} entidades")
        else:
            print("‚ö†Ô∏è No se extrajeron entidades.")

    @traceable(name="SistemaColaba.generar_rubrica", run_type="chain")
    def generar_rubrica(self, prompt: str, archivo_salida: str = None, nivel: str = "avanzado") -> str:
        """Flujo completo de generaci√≥n (trazado via OpenTelemetry)"""
        contexto = self.agente_busqueda.procesar_prompt(prompt)
        rubrica = self.agente_rubricador.generar_rubrica(prompt, contexto, nivel)
        
        if archivo_salida:
            with open(archivo_salida, 'w', encoding='utf-8') as f:
                f.write(rubrica)
                f.flush()
                os.fsync(f.fileno())
            size = os.path.getsize(archivo_salida)
            print(f"\nüíæ R√∫brica guardada en: {archivo_salida} ({size/1024:.1f} KB)")
            
        return rubrica


# ============================================================================
# EJEMPLO DE USO
# ============================================================================

if __name__ == "__main__":
    # Inicializar sistema
    colaba = SistemaColabaQdrant()

    # =========================================================================
    # METADATOS IEEE LOM PARA LA NORMATIVA (Basado en an√°lisis de ontolog√≠a)
    # =========================================================================
    
    metadatos_normativa_lom = {
        "general": {
            "identifier": {"catalog": "colaba-qdrant", "entry": "norm-apuntes-001"},
            "title": "Normativa de Calidad para la Elaboraci√≥n de Apuntes de C√°tedra",
            "language": "es",
            "description": "Criterios de evaluaci√≥n para desarrollo de conceptos, referencias bibliogr√°ficas y recursos web en apuntes universitarios",
            "keyword": ["apuntes", "calidad", "evaluaci√≥n", "bibliograf√≠a", "recursos web", "precisi√≥n conceptual"],
            "structure": "hierarchical",
            "aggregationLevel": "2"
        },
        "lifeCycle": {
            "version": "1.0",
            "status": "final",
            "contribute": [{"role": "author", "entity": "Sistema Colaba Qdrant", "date": "2026-01-29"}]
        },
        "educational": {
            "intendedEndUserRole": ["teacher", "author"],
            "context": ["higher education"],
            "learningResourceType": ["policy document", "evaluation rubric", "reference"],
            "typicalAgeRange": "18+",
            "semanticDensity": "high",
            "interactivityType": "expositive"
        },
        "rights": {
            "cost": "no",
            "copyrightAndOtherRestrictions": "yes",
            "description": "Uso institucional acad√©mico"
        },
        "relation": [
            {"kind": "isBasedOn", "resource": {"identifier": "IEEE_LOM_1484.12.1-2020"}}
        ],
        "classification": [
            {
                "purpose": "educational objective",
                "taxonPath": {
                    "source": "Normativa Interna",
                    "taxon": [
                        {"id": "art1", "entry": "Desarrollo de Conceptos"},
                        {"id": "art2", "entry": "Referencias Bibliogr√°ficas"},
                        {"id": "art3", "entry": "Recursos y Enlaces Web"}
                    ]
                }
            }
        ]
    }
    
    # Validar metadatos IEEE LOM
    es_valido, errores = validar_metadatos_lom(metadatos_normativa_lom)
    if es_valido:
        print("‚úÖ Metadatos IEEE LOM v√°lidos")
    else:
        print(f"‚ö†Ô∏è Errores en metadatos: {errores}")

    # 1. Definir Normativa de Calidad de Apuntes (con metadatos IEEE LOM)
    normativa_apuntes = f"""
    NORMATIVA DE CALIDAD PARA LA ELABORACI√ìN DE APUNTES DE C√ÅTEDRA
    
    === METADATOS IEEE LOM ===
    Identificador: {metadatos_normativa_lom['general']['identifier']['entry']}
    T√≠tulo: {metadatos_normativa_lom['general']['title']}
    Idioma: {metadatos_normativa_lom['general']['language']}
    Estructura: {metadatos_normativa_lom['general']['structure']}
    Contexto Educativo: {metadatos_normativa_lom['educational']['context']}
    Tipo de Recurso: {metadatos_normativa_lom['educational']['learningResourceType']}
    Densidad Sem√°ntica: {metadatos_normativa_lom['educational']['semanticDensity']}
    
    === REQUISITOS M√çNIMOS PARA APROBACI√ìN ===
    Todo apunte debe cumplir con los siguientes requisitos m√≠nimos observables:
    
    1. ESTRUCTURA VISIBLE:
       - T√≠tulo del tema claramente identificado
       - Nombre del autor y fecha de elaboraci√≥n
       - √çndice o secciones numeradas (para documentos > 3 p√°ginas)
       - P√°rrafos diferenciados con separaci√≥n visual
    
    2. EXTENSI√ìN M√çNIMA:
       - Al menos 1 p√°gina por unidad tem√°tica principal
       - M√≠nimo 500 palabras por concepto clave desarrollado
    
    3. FUENTES DOCUMENTADAS:
       - M√≠nimo 2 referencias bibliogr√°ficas por tema
       - Formato de citaci√≥n consistente (APA, IEEE u otro)
       - Distinci√≥n clara entre citas textuales y par√°frasis
    
    4. CONTENIDO VERIFICABLE:
       - Sin errores conceptuales en definiciones clave
       - Terminolog√≠a t√©cnica usada correctamente
       - Al menos 1 ejemplo propio por concepto abstracto
    
    === CONTENIDO NORMATIVO ===

    ART√çCULO 1: DESARROLLO DE CONCEPTOS
    Los apuntes deben presentar el contenido disciplinar con rigor acad√©mico y claridad expositiva.
    
    Criterios de evaluaci√≥n con EVIDENCIAS OBSERVABLES:
    
    - Precisi√≥n conceptual: 
      EVIDENCIA: Las definiciones coinciden con las fuentes bibliogr√°ficas citadas.
      INDICADOR: 0 errores conceptuales graves en t√©rminos clave.
    
    - Profundidad del desarrollo:
      EVIDENCIA: Cada concepto incluye: definici√≥n + explicaci√≥n + al menos 1 ejemplo.
      INDICADOR: M√≠nimo 3 niveles de detalle (qu√© es, c√≥mo funciona, para qu√© sirve).
    
    - Secuenciaci√≥n l√≥gica:
      EVIDENCIA: Uso de conectores l√≥gicos entre p√°rrafos (por lo tanto, en consecuencia, etc.)
      INDICADOR: El lector puede seguir la argumentaci√≥n sin saltos abruptos.
    
    - Elaboraci√≥n personal:
      EVIDENCIA: Presencia de res√∫menes, esquemas o diagramas propios del autor.
      INDICADOR: Al menos 1 elemento visual propio (tabla, diagrama, esquema) por tema.
      NOTA: "Elaboraci√≥n personal" se mide por la presencia de s√≠ntesis y reformulaci√≥n, 
            NO por el rendimiento posterior del estudiante.
    
    - S√≠ntesis:
      EVIDENCIA: Inclusi√≥n de resumen o conclusi√≥n al final de cada secci√≥n.
      INDICADOR: Resumen de m√°ximo 100 palabras por secci√≥n principal.

    ART√çCULO 2: REFERENCIAS BIBLIOGR√ÅFICAS
    Todo material docente debe estar fundamentado en fuentes acad√©micas reconocidas.
    
    Criterios de evaluaci√≥n con EVIDENCIAS OBSERVABLES:
    
    - Citaci√≥n correcta:
      EVIDENCIA: Todas las citas siguen un formato est√°ndar consistente.
      INDICADOR: 100% de las citas con formato APA, IEEE o ISO 690.
    
    - Pertinencia temporal:
      EVIDENCIA: Fecha de publicaci√≥n de las fuentes consultadas.
      INDICADOR: Al menos 50% de las referencias de los √∫ltimos 10 a√±os.
    
    - Clasificaci√≥n de fuentes:
      EVIDENCIA: Identificaci√≥n expl√≠cita de bibliograf√≠a "b√°sica" vs "complementaria".
      INDICADOR: Secci√≥n diferenciada o marcado visual de cada tipo.
    
    - Diversidad de fuentes:
      EVIDENCIA: Tipos de fuentes utilizadas (libros, art√≠culos, recursos web).
      INDICADOR: M√≠nimo 2 tipos diferentes de fuentes.

    ART√çCULO 3: RECURSOS Y ENLACES WEB
    Los recursos digitales complementarios deben enriquecer el aprendizaje.
    
    Criterios de evaluaci√≥n con EVIDENCIAS OBSERVABLES:
    
    - Validez de enlaces:
      EVIDENCIA: Comprobaci√≥n de que los enlaces funcionan (HTTP 200).
      INDICADOR: 100% de enlaces activos al momento de la entrega.
    
    - Descripci√≥n de recursos:
      EVIDENCIA: Cada enlace tiene descripci√≥n de 1-2 oraciones.
      INDICADOR: Ning√∫n enlace "suelto" sin contexto explicativo.
    
    - Fuentes confiables:
      EVIDENCIA: Dominio del sitio web (edu, gov, org, instituciones reconocidas).
      INDICADOR: Al menos 70% de enlaces a fuentes institucionales o acad√©micas.
    
    - Integraci√≥n con contenido:
      EVIDENCIA: El recurso web est√° mencionado en el texto principal.
      INDICADOR: Cada enlace tiene una referencia expl√≠cita en el cuerpo del apunte.
    
    === ESCALA DE CALIFICACI√ìN ===
    4 - EXCELENTE: Cumple todos los indicadores + aporta elementos adicionales de valor.
    3 - SATISFACTORIO: Cumple todos los requisitos m√≠nimos e indicadores principales.
    2 - EN DESARROLLO: Cumple requisitos m√≠nimos pero falla en 1-2 indicadores.
    1 - INSUFICIENTE: No cumple requisitos m√≠nimos OR falla en 3+ indicadores.
    """

    # 2. Definir Est√°ndar IEEE LOM (Estructura completa seg√∫n IEEE 1484.12.1-2020)
    estandar_lom = f"""
    Est√°ndar IEEE LOM (Learning Object Metadata) - IEEE 1484.12.1-2020
    
    Este est√°ndar define metadatos para describir recursos educativos (objetos de aprendizaje).
    
    CATEGOR√çAS DEL ESQUEMA IEEE LOM:
    
    1. GENERAL - Informaci√≥n general del recurso
       - Identificador (cat√°logo + entrada)
       - T√≠tulo, idioma, descripci√≥n
       - Palabras clave
       - Estructura: {IEEE_LOM_SCHEMA['general']['structure']}
       - Nivel de agregaci√≥n: {IEEE_LOM_SCHEMA['general']['aggregationLevel']}
    
    2. CICLO DE VIDA (LifeCycle)
       - Versi√≥n y estado
       - Estados v√°lidos: {IEEE_LOM_SCHEMA['lifeCycle']['status']}
       - Contribuyentes (rol, entidad, fecha)
    
    3. EDUCATIVA (Educational) - Caracter√≠sticas pedag√≥gicas
       - Roles de usuario: {list(IEEE_LOM_ROLES.keys())}
       - Contextos: {list(IEEE_LOM_CONTEXTS.keys())}
       - Tipos de recurso: {IEEE_LOM_RESOURCE_TYPES[:5]}...
       - Tipo de interactividad: {IEEE_LOM_SCHEMA['educational']['interactivityType']}
       - Densidad sem√°ntica: {IEEE_LOM_SEMANTIC_DENSITY}
       - Dificultad: {IEEE_LOM_SCHEMA['educational']['difficulty']}
    
    4. DERECHOS (Rights)
       - Costo: s√≠/no
       - Restricciones de copyright
       - Descripci√≥n de licencia
    
    5. RELACI√ìN (Relation)
       - Tipos: isBasedOn, requires, references, isPartOf
       - Permite vincular recursos educativos relacionados
    
    6. CLASIFICACI√ìN (Classification)
       - Prop√≥sito: disciplina, prerequisito, objetivo educativo
       - TaxonPath: sistema de clasificaci√≥n jer√°rquico
    """

    print("\nüìö Cargando documentos normativos en Qdrant...")
    print(f"   üìã Ontolog√≠a utilizada: IEEE LOM (IEEE 1484.12.1-2020)")
    print(f"   üìù Puntuaci√≥n ontolog√≠a: 4.25/5.00 (Ver SKILL.md para an√°lisis completo)")
    colaba.cargar_normativa(normativa_apuntes)
    colaba.cargar_normativa(estandar_lom)

    # 3. Seleccionar nivel educativo (INTERACTIVO)
    print("\n" + "="*60)
    print("üìä SELECCI√ìN DE NIVEL EDUCATIVO")
    print("="*60)
    print("\nNiveles disponibles:")
    for key, val in NIVELES_ESTUDIANTE.items():
        print(f"  {key}: {val['nombre']} (m√°x. {val['max_criterios']} criterios)")
    
    print("\nOpciones r√°pidas: 1=primer_a√±o, 2=avanzado, 3=posgrado")
    nivel_input = input("Nivel del estudiante [2=avanzado]: ").strip() or "2"
    
    nivel_map = {"1": "primer_a√±o", "2": "avanzado", "3": "posgrado"}
    nivel_seleccionado = nivel_map.get(nivel_input, nivel_input)
    
    # Validar nivel
    if nivel_seleccionado not in NIVELES_ESTUDIANTE:
        print(f"‚ö†Ô∏è Nivel '{nivel_seleccionado}' no reconocido. Usando 'avanzado'.")
        nivel_seleccionado = "avanzado"
    
    print(f"\n‚úÖ Nivel seleccionado: {NIVELES_ESTUDIANTE[nivel_seleccionado]['nombre']}")
    
    # 4. Generar R√∫brica
    print("\nüìã Generando r√∫brica de evaluaci√≥n de APUNTES DE C√ÅTEDRA...")
    prompt_usuario = """
    Genera una r√∫brica detallada para evaluar la CALIDAD DE APUNTES DE C√ÅTEDRA.
    B√°sate en la 'NORMATIVA DE CALIDAD PARA LA ELABORACI√ìN DE APUNTES' y usa la estructura de metadatos de 'IEEE LOM' donde aplique.
    
    Aseg√∫rate de incluir criterios espec√≠ficos para:
    1. Desarrollo de Conceptos (Precisi√≥n, Profundidad)
    2. Bibliograf√≠a (Citaci√≥n, Pertinencia)
    3. Links y Recursos Web (Validez, Calidad)
    """
    
    rubrica = colaba.generar_rubrica(
        prompt=prompt_usuario,
        archivo_salida="rubrica_calidad_apuntes_qdrant.txt",
        nivel=nivel_seleccionado
    )
    
    print("\n‚úÖ Proceso finalizado.")

